# multimodal-emotion

# Multi-Modal Emotion Detection ğŸ­

A comprehensive emotion detection system that analyzes emotions across multiple modalities: text, audio, and images using state-of-the-art transformer models.

## Features

- **Text Emotion Detection**: Using BERT/RoBERTa for text-based emotion analysis
- **Audio Emotion Detection**: Using Wav2Vec2 for speech emotion recognition
- **Image Emotion Detection**: Using Vision Transformer (ViT) for facial emotion recognition
- **Multi-Modal Fusion**: Combining predictions from all modalities
- **Real-time Processing**: API endpoints for live emotion detection
- **Batch Processing**: Efficient processing of large datasets

## Supported Emotions

- Anger ğŸ˜ 
- Disgust ğŸ¤¢
- Fear ğŸ˜¨
- Joy ğŸ˜Š
- Sadness ğŸ˜¢
- Surprise ğŸ˜²
- Neutral ğŸ˜

## Installation

```bash

git clone https://github.com/your-username/multimodal-emotion-detection.git
cd multimodal-emotion-detection
pip install -r requirements.txt

```
